{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNEflow basic example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing data\n",
    "\n",
    "### 1.1.from MNE epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use MNE-python, all you need is to provide your epochs file (or list of epoch files) to mneflow.produce_tfrecords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "#get epochs using your mne-python pipeline\n",
    "import os\n",
    "from time import time\n",
    "import mne\n",
    "from mne.datasets import multimodal\n",
    "os.chdir('/m/nbe/work/zubarei1/mneflow/')\n",
    "import mneflow\n",
    "\n",
    "mne.set_log_level(verbose='CRITICAL')\n",
    "\n",
    "fname_raw = os.path.join(multimodal.data_path(), 'multimodal_raw.fif')\n",
    "raw = mne.io.read_raw_fif(fname_raw)\n",
    "\n",
    "cond = raw.acqparser.get_condition(raw, None)\n",
    "#get the list of condition names\n",
    "condition_names = [k for c in cond for k,v in c['event_id'].items()]\n",
    "\n",
    "epochs_list = [mne.Epochs(raw, **c) for c in cond]\n",
    "\n",
    "#here we concatenate epochs because each input file contains just one condition\n",
    "#otherwise mneflow.produce_tfrecords can handle a list of epochs objects\n",
    "epochs = mne.concatenate_epochs(epochs_list)\n",
    "#pick only planar gradiometers\n",
    "epochs = epochs.pick_types(meg='grad')\n",
    "#print(epochs.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert epochs to TFRecord format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file found, restoring\n"
     ]
    }
   ],
   "source": [
    "#Specify import options\n",
    "\n",
    "import_opt = dict(savepath='../tfr/', #path where TFR files will be saved\n",
    "                   out_name='mne_sample_epochs1', #name of TFRecords files\n",
    "                   fs=600,\n",
    "                   input_type='trials',\n",
    "                   target_type='int',\n",
    "                   picks = {'meg':'grad'},\n",
    "                   scale=True, #apply baseline_scaling\n",
    "                   crop_baseline=True, #remove baseline interval after scaling\n",
    "                   decimate = 2,\n",
    "                   scale_interval=(0,60), #indices in time axis corresponding to baseline interval\n",
    "                   val_size=0.15, #validation set size set to 15% of all data\n",
    "                   overwrite=False) \n",
    "\n",
    "\n",
    "#write TFRecord files and metadata file to disk\n",
    "#meta = mneflow.produce_tfrecords([epochs],**import_opt)  \n",
    "meta = mneflow.produce_tfrecords([epochs],**import_opt)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other import options\n",
    "### 1.2 Saved mne.epochs (*-epo.fif) files\n",
    "Alternatively, if your epochs are saved to disk provide a str (or list of str) with path(s) to your -epo.fif files\n",
    "\n",
    "e.g. this will work\n",
    "\n",
    "```python\n",
    "epochs.save('test_saved_epochs.fif')\n",
    "meta = mneflow.produce_tfrecords('test_saved_epochs.fif',**opt)\n",
    "```\n",
    "### 1.3. Arrays in *.mat or *.npz format\n",
    "if the first argument is str mneflow.produce_tfrecords can also accept *.mat or *.npz format\n",
    "\n",
    "e.g.\n",
    "\n",
    "```python\n",
    "data_path = '/m/nbe/scratch/braindata/izbrv/detection_data/'\n",
    "filenames = [data_path +'sub' + str(i) + '-grad.npz' for i in range(1,4)]\n",
    "meta = mneflow.produce_tfrecords(filenames,**opt)\n",
    "```\n",
    "In this case, specify iput_type='array', and also provide array_keys keyword argument\n",
    "\n",
    "e.g. \n",
    "\n",
    "```python\n",
    "array_keys={'X':'my_data_samples','y':'my_labels'}\n",
    "```\n",
    "\n",
    "### 1.4. Tuple of (data, labels)\n",
    "Finally, if you have a more complex preprocessing pipeline, you can feed you data and labels as a tuple of arrays\n",
    "\n",
    "```python\n",
    "X = epochs.get_data()\n",
    "y = epochs.events[:,2]\n",
    "meta = mneflow.produce_tfrecords((X,y),**opt)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Initialize the dataset object using the generated metadata file\n",
    "\n",
    "The dataset object includes several methods that allow experimenting with the dataset without the need to repeat the preprocessing or overwriting the TFRecord files each time.\n",
    "\n",
    "For example, you can train the model using any subset of classes, channels or reduce the sampling rate by decimating across the time domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1024 16:32:25.760249 140697714599680 deprecation_wrapper.py:119] From /m/nbe/work/zubarei1/mneflow/mneflow/data.py:137: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "W1024 16:32:25.786967 140697714599680 deprecation.py:323] From /m/nbe/work/zubarei1/mneflow/mneflow/data.py:111: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    }
   ],
   "source": [
    "dataset = mneflow.Dataset(meta, train_batch = 200, class_subset=None, pick_channels=None, decim=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Choose from already implemented models\n",
    "\n",
    "MNEflow pipeline consists of three major parts:\n",
    "1. dataset\n",
    "2. optimizer\n",
    "3. computational graph\n",
    "\n",
    "Each part has its own set of hyper-parameters and methods that can be tuned. See help for mneflow.Dataset\n",
    "and mneflow.Optimizer and mneflow.models.Model for more details.\n",
    "In this example will we use LF-CNN network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify optimizer parmeters\n",
    "optimizer_params = dict(l1_lambda=3e-4,learn_rate=3e-4)\n",
    "\n",
    "optimizer = mneflow.Optimizer(**optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1024 16:32:25.829552 140697714599680 deprecation_wrapper.py:119] From /m/nbe/work/zubarei1/mneflow/mneflow/models.py:44: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W1024 16:32:25.834677 140697714599680 deprecation_wrapper.py:119] From /m/nbe/work/zubarei1/mneflow/mneflow/models.py:45: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1024 16:32:25.835964 140697714599680 deprecation.py:323] From /m/nbe/work/zubarei1/mneflow/mneflow/models.py:68: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "W1024 16:32:25.893560 140697714599680 deprecation_wrapper.py:119] From /m/nbe/work/zubarei1/mneflow/mneflow/models.py:49: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n",
      "W1024 16:32:25.894151 140697714599680 deprecation.py:323] From /m/nbe/work/zubarei1/mneflow/mneflow/models.py:49: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
      "W1024 16:32:25.894592 140697714599680 deprecation.py:323] From /m/nbe/work/zubarei1/mneflow/mneflow/models.py:49: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
      "W1024 16:32:25.899166 140697714599680 deprecation_wrapper.py:119] From /m/nbe/work/zubarei1/mneflow/mneflow/layers.py:266: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0: (?, 204, 151)\n",
      "de-mix init : OK\n",
      "dmx (?, 204, 1, 64)\n",
      "lf-inp "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1024 16:32:25.943397 140697714599680 deprecation.py:506] From /m/nbe/work/zubarei1/mneflow/mneflow/layers.py:63: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1024 16:32:25.954068 140697714599680 deprecation_wrapper.py:119] From /m/nbe/work/zubarei1/mneflow/mneflow/models.py:85: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W1024 16:32:25.963893 140697714599680 deprecation_wrapper.py:119] From /m/nbe/work/zubarei1/mneflow/mneflow/optimize.py:76: The name tf.losses.softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.softmax_cross_entropy instead.\n",
      "\n",
      "W1024 16:32:25.987668 140697714599680 deprecation.py:323] From /u/62/zubarei1/unix/.conda/envs/py3ml/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1024 16:32:26.000669 140697714599680 deprecation_wrapper.py:119] From /m/nbe/work/zubarei1/mneflow/mneflow/optimize.py:124: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W1024 16:32:26.007218 140697714599680 deprecation_wrapper.py:119] From /m/nbe/work/zubarei1/mneflow/mneflow/optimize.py:138: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 204, 1, 64)\n",
      "conv init : OK\n",
      "lf-inp (?, 204, 1, 64)\n",
      "f: (17, 1, 64, 1)\n",
      "lf-out (?, 41, 1, 64)\n",
      "fc ::: 2624 8\n",
      "fc init : OK\n",
      "X: (?, 204, 151, 1)\n",
      "y_pred: (?, 8)\n",
      "L1 penalty applied to weights\n",
      "Initialization complete!\n"
     ]
    }
   ],
   "source": [
    "#specify parameters specific to LF-CNN\n",
    "lf_params = dict(n_ls=64, #number of latent factors\n",
    "              filter_length=17, #convolutional filter length in time samples\n",
    "              pooling = 5, #pooling factor\n",
    "              stride = 5, #stride parameter for pooling layer\n",
    "              padding = 'SAME',\n",
    "              dropout = .5,\n",
    "              model_path = import_opt['savepath']) #path for storing the saved model\n",
    "\n",
    "#initialize the model using the dataset and optimizer objects, and the hyper-parameter dictionary\n",
    "model = mneflow.models.LFCNN(dataset, optimizer, lf_params)\n",
    "\n",
    "#this will initialize the iterators over the dataset,the computational graph and the optimizer\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0, tr_loss 2.63277, tr_acc 0.145 v_loss 2.5999, v_acc 0.148936\n",
      "i 250, tr_loss 1.47392, tr_acc 0.715 v_loss 1.69491, v_acc 0.553191\n",
      "i 500, tr_loss 0.779655, tr_acc 0.955 v_loss 1.01218, v_acc 0.808511\n",
      "i 750, tr_loss 0.454264, tr_acc 1 v_loss 0.860577, v_acc 0.808511\n",
      "i 1000, tr_loss 0.480628, tr_acc 1 v_loss 0.750533, v_acc 0.861702\n",
      "i 1250, tr_loss 0.442505, tr_acc 1 v_loss 0.74687, v_acc 0.904255\n",
      "i 1500, tr_loss 0.413581, tr_acc 1 v_loss 0.65524, v_acc 0.914894\n",
      "i 1750, tr_loss 0.390058, tr_acc 1 v_loss 0.635465, v_acc 0.925532\n",
      "i 2000, tr_loss 0.358462, tr_acc 1 v_loss 0.597493, v_acc 0.925532\n",
      "i 2250, tr_loss 0.346232, tr_acc 1 v_loss 0.579263, v_acc 0.914894\n",
      "i 2500, tr_loss 0.324752, tr_acc 1 v_loss 0.526663, v_acc 0.946809\n",
      "i 2750, tr_loss 0.303648, tr_acc 1 v_loss 0.523416, v_acc 0.925532\n",
      "i 3000, tr_loss 0.284246, tr_acc 1 v_loss 0.497532, v_acc 0.925532\n",
      "Trained in 126.17s\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "start = time()\n",
    "model.train(n_iter=3000,eval_step=250,min_delta=1e-6,early_stopping=1)\n",
    "stop = time() - start\n",
    "print('Trained in {:.2f}s'.format(stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Explore the trained model parameters\n",
    "LFCNN allows to interpret the trained parameters in terms of toporaphies and the spectral properties of the latent sources contributing to each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (6946,204) and (151,64) not aligned: 204 (dim 1) != 151 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-53104bcb5298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'patterns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensor_layout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Vectorview-grad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspectra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/m/nbe/work/zubarei1/mneflow/mneflow/models.py\u001b[0m in \u001b[0;36mcompute_patterns\u001b[0;34m(self, megdata, output, norm_spect)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlat_tcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'patterns'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mledoit_wolf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (6946,204) and (151,64) not aligned: 204 (dim 1) != 151 (dim 0)"
     ]
    }
   ],
   "source": [
    "model.compute_patterns('patterns')\n",
    "f = model.plot_patterns(sensor_layout='Vectorview-grad', sorting='best', spectra=False, scale=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix allows to identify analyze whether cetrain classes \n",
    "#are systematically harder to classify \n",
    "f2 = model.plot_cm(dataset='validation', class_names=condition_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meta['y_shape'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
