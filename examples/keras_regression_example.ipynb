{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file found, restoring\n"
     ]
    }
   ],
   "source": [
    "#%pylab inline\n",
    "#get epochs using your mne-python pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=PendingDeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import mne\n",
    "\n",
    "#os.chdir('/m/nbe/project/rtmeg/problearn/mneflow/')\n",
    "os.chdir('/u/20/vranoug1/unix/OPM-BCI/mneflow-dev/mneflow/')\n",
    "import mneflow\n",
    "from mneflow import keras_models\n",
    "\n",
    "from mneflow.keras_utils import plot_metrics, plot_output, plot_history_v2\n",
    "from mneflow.keras_utils import r_square, soft_acc, rmse\n",
    "\n",
    "# Force enable eager execution after importing mneflow\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "mne.set_log_level(verbose='CRITICAL')\n",
    "\n",
    "\n",
    "path = '/m/nbe/work/vranoug1/OPM-BCI/datasets/'\n",
    "fname = 'sim_2_erps_50nA.npz'\n",
    "\n",
    "\n",
    "import_opt = dict(fs=500,\n",
    "                  savepath='../tfr/',\n",
    "                  out_name=fname+'0',\n",
    "                  input_type='trials',\n",
    "                  target_type='float',\n",
    "                  val_size=0.2,\n",
    "                  array_keys={'X': 'X', 'y': 'y'},\n",
    "                  # picks=None, target_picks=None,\n",
    "                  scale=True,\n",
    "                  scale_interval=None,\n",
    "                  # crop_baseline=True,\n",
    "                  decimate=None,\n",
    "                  bp_filter=False,\n",
    "                  overwrite=False,\n",
    "                  test_set='holdout')\n",
    "\n",
    "meta = mneflow.produce_tfrecords([path+fname], **import_opt)\n",
    "dataset = mneflow.Dataset(meta, train_batch=100, class_subset=None, pick_channels=None, decim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "/u/20/vranoug1/unix/.conda/envs/py3ml2/lib/python3.7/site-packages/mneflow/__init__.py\n",
      "tf version: 2.0.0\n",
      "executing eagerly: True\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "sys.path\n",
    "print('---------\\n'+mneflow.__file__)\n",
    "print('tf version: '+tf.__version__)\n",
    "print('executing eagerly: '+str(tf.executing_eagerly())+'\\n---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify optimizer parmeters\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=3e-4)\n",
    "\n",
    "# specify model parameters\n",
    "graph_specs = dict(n_ls=64,  # number of latent factors\n",
    "                   filter_length=17,  # convolutional filter length\n",
    "                   pooling=5,  # convlayer pooling factor\n",
    "                   stride=5,  # stride parameter for pooling layer\n",
    "                   padding='SAME',\n",
    "                   dropout=.5,\n",
    "                   nonlin=tf.nn.relu,\n",
    "                   pool_type='max',\n",
    "                   out_dim=np.prod(meta['y_shape']),\n",
    "                   axis=1,\n",
    "                   y_shape=meta['y_shape'],\n",
    "                   model_path = import_opt['savepath'],  # not used at the moment\n",
    "                   # regularization parameters\n",
    "                   l1=3e-4,\n",
    "                   l2=0,\n",
    "                   # LSTM parameters\n",
    "                   rnn_units=np.prod(meta['y_shape']),\n",
    "                   rnn_dropout=0.0,\n",
    "                   rnn_nonlin='tanh',\n",
    "                   rnn_rec_nonlin='tanh',\n",
    "                   rnn_forget_bias=True,\n",
    "                   rnn_seq=True,\n",
    "                   unroll=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LFLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de-mix init : OK\n",
      "lstm init : OK\n",
      "fc init : OK\n"
     ]
    }
   ],
   "source": [
    "model = keras_models.LFLSTM(graph_specs, dataset)\n",
    "loss_f = tf.compat.v1.losses.mean_squared_error\n",
    "\n",
    "# % builtin\n",
    "model.compile(loss=loss_f, optimizer=optim, metrics=[r_square, soft_acc, rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 102, 300]\n",
      "input x0 (?, 102, 300, 1)\n",
      "input x0 (?, 102, 300, 1)\n",
      "de-mix built : OK\n",
      "dmx (?, 300, 1, 64)\n",
      "demix dmx (?, 300, 1, 64)\n",
      "reshaped dmx (?, 300, 64, 1)\n",
      "conv build : OK\n",
      "varconv (?, 60, 64, 1)\n",
      "reshaped varconv (?, 1, 3840)\n",
      "lstm (?, 1, 64)\n",
      "fc ::: 64 1\n",
      "fc build : OK\n",
      "fc y_ (?, 1)\n",
      "Train for 100 steps, validate for 1 steps\n",
      "Epoch 1/30000\n",
      "[None, 102, 300]\n",
      "input x0 (?, 102, 300, 1)\n",
      "input x0 (?, 102, 300, 1)\n",
      "dmx (?, 300, 1, 64)\n",
      "demix dmx (?, 300, 1, 64)\n",
      "reshaped dmx (?, 300, 64, 1)\n",
      "varconv (?, 60, 64, 1)\n",
      "reshaped varconv (?, 1, 3840)\n",
      "lstm (?, 1, 64)\n",
      "fc y_ (?, 1)\n",
      "[None, 102, 300]\n",
      "input x0 (?, 102, 300, 1)\n",
      "input x0 (?, 102, 300, 1)\n",
      "demix dmx (?, 300, 1, 64)\n",
      "reshaped dmx (?, 300, 64, 1)\n",
      "varconv (?, 60, 64, 1)\n",
      "reshaped varconv (?, 1, 3840)\n",
      "lstm (?, 1, 64)\n",
      "fc y_ (?, 1)\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 6.2647 - r_square: -22.6590 - soft_acc: 0.0023 - rmse: 1.0741[None, 102, 300]\n",
      "input x0 (?, 102, 300, 1)\n",
      "input x0 (?, 102, 300, 1)\n",
      "dmx (?, 300, 1, 64)\n",
      "demix dmx (?, 300, 1, 64)\n",
      "reshaped dmx (?, 300, 64, 1)\n",
      "varconv (?, 60, 64, 1)\n",
      "reshaped varconv (?, 1, 3840)\n",
      "lstm (?, 1, 64)\n",
      "fc y_ (?, 1)\n",
      "100/100 [==============================] - 76s 762ms/step - loss: 6.2484 - r_square: -22.5218 - soft_acc: 0.0023 - rmse: 1.0706 - val_loss: 4.1986 - val_r_square: -0.3594 - val_soft_acc: 0.0000e+00 - val_rmse: 0.2978\n",
      "Epoch 2/30000\n",
      "100/100 [==============================] - 74s 740ms/step - loss: 4.7977 - r_square: -14.7770 - soft_acc: 0.0046 - rmse: 0.8184 - val_loss: 3.6839 - val_r_square: -0.0046 - val_soft_acc: 0.0000e+00 - val_rmse: 0.2560\n",
      "Epoch 3/30000\n",
      "100/100 [==============================] - 73s 727ms/step - loss: 4.5479 - r_square: -17.7336 - soft_acc: 0.0040 - rmse: 0.8733 - val_loss: 3.3348 - val_r_square: -0.0453 - val_soft_acc: 0.0100 - val_rmse: 0.2611\n",
      "Epoch 4/30000\n",
      "100/100 [==============================] - 74s 736ms/step - loss: 4.5085 - r_square: -22.6271 - soft_acc: 0.0031 - rmse: 1.0002 - val_loss: 3.0742 - val_r_square: -0.1176 - val_soft_acc: 0.0100 - val_rmse: 0.2700\n",
      "Epoch 5/30000\n",
      "100/100 [==============================] - 73s 731ms/step - loss: 3.9710 - r_square: -17.1053 - soft_acc: 0.0035 - rmse: 0.8796 - val_loss: 2.9111 - val_r_square: -1.2630 - val_soft_acc: 0.0200 - val_rmse: 0.3842\n",
      "Epoch 6/30000\n",
      "100/100 [==============================] - 73s 726ms/step - loss: 3.6425 - r_square: -16.2525 - soft_acc: 0.0029 - rmse: 0.8450 - val_loss: 2.6205 - val_r_square: -0.6179 - val_soft_acc: 0.0100 - val_rmse: 0.3249\n",
      "Epoch 7/30000\n",
      "100/100 [==============================] - 76s 756ms/step - loss: 3.8763 - r_square: -22.9999 - soft_acc: 0.0045 - rmse: 0.9632 - val_loss: 2.6544 - val_r_square: -3.3344 - val_soft_acc: 0.0100 - val_rmse: 0.5317\n",
      "Epoch 8/30000\n",
      "100/100 [==============================] - 73s 730ms/step - loss: 3.3799 - r_square: -18.0457 - soft_acc: 0.0034 - rmse: 0.8550 - val_loss: 2.3395 - val_r_square: -1.0227 - val_soft_acc: 0.0100 - val_rmse: 0.3632\n",
      "Epoch 9/30000\n",
      "100/100 [==============================] - 73s 730ms/step - loss: 3.0118 - r_square: -13.4732 - soft_acc: 0.0039 - rmse: 0.7880 - val_loss: 2.1308 - val_r_square: -0.3255 - val_soft_acc: 0.0300 - val_rmse: 0.2940\n",
      "Epoch 10/30000\n",
      "100/100 [==============================] - 75s 752ms/step - loss: 2.8134 - r_square: -12.9144 - soft_acc: 0.0035 - rmse: 0.7942 - val_loss: 1.9712 - val_r_square: -0.1446 - val_soft_acc: 0.0100 - val_rmse: 0.2732\n",
      "Epoch 11/30000\n",
      "100/100 [==============================] - 75s 751ms/step - loss: 2.5799 - r_square: -11.5448 - soft_acc: 0.0050 - rmse: 0.7333 - val_loss: 1.9618 - val_r_square: -1.5502 - val_soft_acc: 0.0100 - val_rmse: 0.4079\n",
      "Epoch 12/30000\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 2.7544 - r_square: -15.9486 - soft_acc: 0.0038 - rmse: 0.8581 - val_loss: 1.7449 - val_r_square: -0.0437 - val_soft_acc: 0.0200 - val_rmse: 0.2609\n",
      "Epoch 13/30000\n",
      "100/100 [==============================] - 55s 545ms/step - loss: 2.3474 - r_square: -11.6982 - soft_acc: 0.0045 - rmse: 0.7385 - val_loss: 1.7420 - val_r_square: -2.1033 - val_soft_acc: 0.0000e+00 - val_rmse: 0.4499\n",
      "Epoch 14/30000\n",
      "100/100 [==============================] - 55s 550ms/step - loss: 2.5437 - r_square: -15.4433 - soft_acc: 0.0043 - rmse: 0.8422 - val_loss: 1.7635 - val_r_square: -2.5301 - val_soft_acc: 0.0000e+00 - val_rmse: 0.4798\n",
      "Epoch 15/30000\n",
      "100/100 [==============================] - 55s 550ms/step - loss: 2.3947 - r_square: -14.5039 - soft_acc: 0.0035 - rmse: 0.8329 - val_loss: 1.4796 - val_r_square: -0.4519 - val_soft_acc: 0.0100 - val_rmse: 0.3077\n",
      "Epoch 16/30000\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 2.0482 - r_square: -10.9179 - soft_acc: 0.0060 - rmse: 0.7065 - val_loss: 1.7044 - val_r_square: -5.0686 - val_soft_acc: 0.0000e+00 - val_rmse: 0.6292\n",
      "Epoch 17/30000\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 2.0011 - r_square: -11.6584 - soft_acc: 0.0040 - rmse: 0.7329 - val_loss: 1.3406 - val_r_square: -1.0385 - val_soft_acc: 0.0000e+00 - val_rmse: 0.3646\n",
      "Epoch 18/30000\n",
      "100/100 [==============================] - 55s 547ms/step - loss: 1.9592 - r_square: -11.8167 - soft_acc: 0.0045 - rmse: 0.7525 - val_loss: 1.2603 - val_r_square: -0.6295 - val_soft_acc: 0.0100 - val_rmse: 0.3260\n",
      "Epoch 19/30000\n",
      "100/100 [==============================] - 56s 559ms/step - loss: 1.9592 - r_square: -12.2495 - soft_acc: 0.0054 - rmse: 0.7621 - val_loss: 1.2599 - val_r_square: -1.1115 - val_soft_acc: 0.0000e+00 - val_rmse: 0.3711\n",
      "Epoch 20/30000\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 1.5448 - r_square: -6.7713 - soft_acc: 0.0065 - rmse: 0.5813 - val_loss: 1.0869 - val_r_square: -0.1032 - val_soft_acc: 0.0400 - val_rmse: 0.2683\n",
      "Epoch 21/30000\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.1089 - r_square: -2.1512 - soft_acc: 0.0107 - rmse: 0.4119 - val_loss: 0.9462 - val_r_square: -0.6553 - val_soft_acc: 0.0100 - val_rmse: 0.3286\n",
      "Epoch 22/30000\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 0.9494 - r_square: -1.6998 - soft_acc: 0.0089 - rmse: 0.3937 - val_loss: 0.8424 - val_r_square: -0.6908 - val_soft_acc: 0.0200 - val_rmse: 0.3321\n",
      "Epoch 23/30000\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 0.8448 - r_square: -1.4868 - soft_acc: 0.0097 - rmse: 0.3743 - val_loss: 0.7618 - val_r_square: -0.6338 - val_soft_acc: 0.0300 - val_rmse: 0.3264\n",
      "Epoch 24/30000\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 0.7491 - r_square: -1.0482 - soft_acc: 0.0120 - rmse: 0.3413 - val_loss: 0.6787 - val_r_square: -0.3150 - val_soft_acc: 0.0100 - val_rmse: 0.2929\n",
      "Epoch 25/30000\n",
      "100/100 [==============================] - 54s 536ms/step - loss: 0.6943 - r_square: -1.0534 - soft_acc: 0.0107 - rmse: 0.3389 - val_loss: 0.6487 - val_r_square: -0.6533 - val_soft_acc: 0.0300 - val_rmse: 0.3284\n",
      "Epoch 26/30000\n",
      "100/100 [==============================] - 55s 547ms/step - loss: 0.6370 - r_square: -1.0578 - soft_acc: 0.0105 - rmse: 0.3377 - val_loss: 0.5893 - val_r_square: -0.4571 - val_soft_acc: 0.0300 - val_rmse: 0.3083\n",
      "Epoch 27/30000\n",
      "100/100 [==============================] - 55s 547ms/step - loss: 0.5866 - r_square: -0.9358 - soft_acc: 0.0110 - rmse: 0.3272 - val_loss: 0.5336 - val_r_square: -0.3205 - val_soft_acc: 0.0100 - val_rmse: 0.2935\n",
      "Epoch 28/30000\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 0.5438 - r_square: -0.9598 - soft_acc: 0.0122 - rmse: 0.3271 - val_loss: 0.4958 - val_r_square: -0.3395 - val_soft_acc: 0.0000e+00 - val_rmse: 0.2956\n",
      "Epoch 29/30000\n",
      "100/100 [==============================] - 66s 663ms/step - loss: 0.4964 - r_square: -0.7995 - soft_acc: 0.0123 - rmse: 0.3172 - val_loss: 0.4523 - val_r_square: -0.2052 - val_soft_acc: 0.0000e+00 - val_rmse: 0.2804\n",
      "Epoch 30/30000\n",
      "100/100 [==============================] - 65s 649ms/step - loss: 0.4488 - r_square: -0.5859 - soft_acc: 0.0127 - rmse: 0.2990 - val_loss: 0.4273 - val_r_square: -0.3489 - val_soft_acc: 0.0200 - val_rmse: 0.2966\n",
      "Epoch 31/30000\n",
      "100/100 [==============================] - 67s 672ms/step - loss: 0.4117 - r_square: -0.4677 - soft_acc: 0.0145 - rmse: 0.2832 - val_loss: 0.3784 - val_r_square: -0.0682 - val_soft_acc: 0.0200 - val_rmse: 0.2640\n",
      "Epoch 32/30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 65s 648ms/step - loss: 0.3781 - r_square: -0.3673 - soft_acc: 0.0135 - rmse: 0.2796 - val_loss: 0.3500 - val_r_square: -0.0658 - val_soft_acc: 0.0000e+00 - val_rmse: 0.2637\n",
      "Epoch 33/30000\n",
      " 72/100 [====================>.........] - ETA: 18s - loss: 0.3670 - r_square: -0.5183 - soft_acc: 0.0142 - rmse: 0.2927"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=6)\n",
    "\n",
    "#train the model\n",
    "history = model.fit(dataset.train, validation_data=dataset.val, epochs=30000, steps_per_epoch=100,\n",
    "                    validation_steps=1, callbacks=[stop_early], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "results = model.evaluate(dataset.test, steps=1, verbose=1)\n",
    "plot_history_v2(history, title=model.name.upper(), nepochs=0, nend=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LFCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_models.LFCNN(graph_specs, dataset)\n",
    "loss_f = tf.compat.v1.losses.mean_squared_error\n",
    "\n",
    "# % builtin\n",
    "model.compile(loss=loss_f, optimizer=optim, metrics=[r_square, soft_acc, rmse])\n",
    "\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=6)\n",
    "\n",
    "#train the model\n",
    "history = model.fit(dataset.train, validation_data=dataset.val, epochs=30000, steps_per_epoch=100,\n",
    "                    validation_steps=1, callbacks=[stop_early], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "results = model.evaluate(dataset.test, steps=1, verbose=1)\n",
    "plot_history_v2(history, title=model.name.upper(), nepochs=0, nend=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. VARCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = keras_models.VARCNN(graph_specs, dataset)\n",
    "loss_f = tf.compat.v1.losses.mean_squared_error\n",
    "\n",
    "# % builtin\n",
    "model.compile(loss=loss_f, optimizer=optim, metrics=[r_square, soft_acc, rmse])\n",
    "\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=6)\n",
    "\n",
    "#train the model\n",
    "history = model.fit(dataset.train, validation_data=dataset.val, epochs=30000, steps_per_epoch=100,\n",
    "                    validation_steps=1, callbacks=[stop_early], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "results = model.evaluate(dataset.test, steps=1, verbose=1)\n",
    "plot_history_v2(history, title=model.name.upper(), nepochs=0, nend=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. VARLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_models.VARLSTM(graph_specs, dataset)\n",
    "loss_f = tf.compat.v1.losses.mean_squared_error\n",
    "\n",
    "# % builtin\n",
    "model.compile(loss=loss_f, optimizer=optim, metrics=[r_square, soft_acc, rmse])\n",
    "\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=6)\n",
    "\n",
    "#train the model\n",
    "history = model.fit(dataset.train, validation_data=dataset.val, epochs=30000, steps_per_epoch=100,\n",
    "                    validation_steps=1, callbacks=[stop_early], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "results = model.evaluate(dataset.test, steps=1, verbose=1)\n",
    "plot_history_v2(history, title=model.name.upper(), nepochs=0, nend=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
