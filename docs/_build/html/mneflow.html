

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>MNEflow API &mdash; MNEflow 0.2.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="History" href="changelog.html" />
    <link rel="prev" title="MNEflow" href="intro.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> MNEflow
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">MNEflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro.html#isnatllation">Isnatllation</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro.html#examples">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro.html#references">References</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">MNEflow API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#mneflow-models-basemodel-class">mneflow.models.BaseModel class</a></li>
<li class="toctree-l2"><a class="reference internal" href="#implemented-models">Implemented models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#lfcnn">LFCNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="#varcnn">VARCNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="#eegnet">EEGNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fbcsp-shallownet">FBCSP_ShallowNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deep4">Deep4</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#mneflow-dataset">mneflow.Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mneflow.utils">mneflow.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mneflow.layers">mneflow.layers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">History</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MNEflow</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>MNEflow API</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/mneflow.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="mneflow-api">
<h1>MNEflow API<a class="headerlink" href="#mneflow-api" title="Permalink to this headline">¶</a></h1>
<div class="section" id="mneflow-models-basemodel-class">
<h2>mneflow.models.BaseModel class<a class="headerlink" href="#mneflow-models-basemodel-class" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="mneflow.models.BaseModel">
<em class="property">class </em><code class="descclassname">mneflow.models.</code><code class="descname">BaseModel</code><span class="sig-paren">(</span><em>Dataset</em>, <em>specs</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.BaseModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Parent class for all MNEflow models.</p>
<p>Provides fast and memory-efficient data handling and simplified API.
Custom models can be built by overriding _build_graph and
_set_optimizer methods.</p>
<dl class="method">
<dt id="mneflow.models.BaseModel.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>Dataset</em>, <em>specs</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.BaseModel.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Dataset</strong> (<em>mneflow.Dataset</em>) – <cite>Dataset</cite> object.</p></li>
<li><p><strong>specs</strong> (<em>dict</em>) – Dictionary of model-specific hyperparameters. Must include
at least <cite>model_path</cite> - path for saving a trained model.
See <cite>Model</cite> subclass definitions for details.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.BaseModel.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.BaseModel.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Compile a model.</p>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.BaseModel.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.BaseModel.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Build computational graph using defined placeholder self.X
as input.</p>
<p>Can be overriden in a sub-class for customized architecture.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>y_pred</strong> – Output of the forward pass of the computational graph.
Prediction of the target variable.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.BaseModel.plot_hist">
<code class="descname">plot_hist</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.BaseModel.plot_hist" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot loss history during training.</p>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.BaseModel.train">
<code class="descname">train</code><span class="sig-paren">(</span><em>n_epochs</em>, <em>eval_step=None</em>, <em>val_batch=None</em>, <em>min_delta=1e-06</em>, <em>early_stopping=3</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.BaseModel.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_epochs</strong> (<em>int</em>) – Maximum number of training eopchs.</p></li>
<li><p><strong>eval_step</strong> (<em>int</em><em>, </em><em>None</em>) – iterations per epoch. If None each epoch passes the training set
exactly once</p></li>
<li><p><strong>early_stopping</strong> (<em>int</em>) – Patience parameter for early stopping. Specifies the number
of epochs’s during which validation cost is allowed to
rise before training stops.</p></li>
<li><p><strong>min_delta</strong> (<em>float</em><em>, </em><em>optional</em>) – Convergence threshold for validation cost during training.
Defaults to 1e-6.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.BaseModel.update_log">
<code class="descname">update_log</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.BaseModel.update_log" title="Permalink to this definition">¶</a></dt>
<dd><p>Logs experiment to self.model_path + self.scope + ‘_log.csv’.</p>
<p>If the file exists, appends a line to the existing file.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="implemented-models">
<h2>Implemented models<a class="headerlink" href="#implemented-models" title="Permalink to this headline">¶</a></h2>
<div class="section" id="lfcnn">
<h3>LFCNN<a class="headerlink" href="#lfcnn" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="mneflow.models.LFCNN">
<em class="property">class </em><code class="descclassname">mneflow.models.</code><code class="descname">LFCNN</code><span class="sig-paren">(</span><em>Dataset</em>, <em>specs</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.LFCNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mneflow.models.BaseModel" title="mneflow.models.BaseModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">mneflow.models.BaseModel</span></code></a></p>
<p>LF-CNN. Includes basic parameter interpretation options.</p>
<p>For details see [1].
.. rubric:: References</p>
<p>[1] I. Zubarev, et al., Adaptive neural network classifier for
decoding MEG signals. Neuroimage. (2019) May 4;197:425-434</p>
<dl class="method">
<dt id="mneflow.models.LFCNN.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>Dataset</em>, <em>specs</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.LFCNN.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Dataset</strong> (<em>mneflow.Dataset</em>) – </p></li>
<li><p><strong>specs</strong> (<em>dict</em>) – dictionary of model hyperparameters {</p></li>
<li><p><strong>n_latent</strong> (<em>int</em>) – Number of latent components.
Defaults to 32.</p></li>
<li><p><strong>nonlin</strong> (<em>callable</em>) – Activation function of the temporal convolution layer.
Defaults to tf.nn.relu</p></li>
<li><p><strong>filter_length</strong> (<em>int</em>) – Length of spatio-temporal kernels in the temporal
convolution layer. Defaults to 7.</p></li>
<li><p><strong>pooling</strong> (<em>int</em>) – Pooling factor of the max pooling layer. Defaults to 2</p></li>
<li><p><strong>pool_type</strong> (<em>str {'avg'</em><em>, </em><em>'max'}</em>) – Type of pooling operation. Defaults to ‘max’.</p></li>
<li><p><strong>padding</strong> (<em>str {'SAME'</em><em>, </em><em>'FULL'</em><em>, </em><em>'VALID'}</em>) – Convolution padding. Defaults to ‘SAME’.}</p></li>
<li><p><strong>stride</strong> (<em>int</em>) – </p></li>
<li><p><strong>of the max pooling layer. Defaults to 1.</strong> (<em>Stride</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.LFCNN.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.LFCNN.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Build computational graph using defined placeholder <cite>self.X</cite>
as input.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>y_pred</strong> – Output of the forward pass of the computational graph.
Prediction of the target variable.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.LFCNN.compute_patterns">
<code class="descname">compute_patterns</code><span class="sig-paren">(</span><em>data_path</em>, <em>output='patterns'</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.LFCNN.compute_patterns" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes spatial patterns from filter weights.
Required for visualization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_path</strong> (<em>str</em><em> or </em><em>list of str</em>) – Path to TFRecord files on which the patterns are estimated.</p></li>
<li><p><strong>output</strong> (<em>str {'patterns</em><em>, </em><em>'filters'</em><em>, </em><em>'full_patterns'}</em>) – <p>String specifying the output.</p>
<p>’filters’ - extracts weights of the spatial filters</p>
<p>’patterns’ - extracts activation patterns, obtained by
left-multipying the spatial filter weights by the (spatial)
data covariance.</p>
<p>’full-patterns’ - additionally multiplies activation
patterns by the precision (inverse covariance) of the
latent sources</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>self.patterns</em> – spatial filters or activation patterns, depending on the
value of ‘output’ parameter.</p></li>
<li><p><em>self.lat_tcs</em> – time courses of latent sourses.</p></li>
<li><p><em>self.filters</em> – temporal convolutional filter coefficients.</p></li>
<li><p><em>self.out_weights</em> – weights of the output layer.</p></li>
<li><p><em>self.rfocs</em> – feature relevances for the output layer.
(See self.get_output_correlations)</p></li>
<li><p><em>Raises</em></p></li>
<li><p><em>——-</em> – AttributeError: If <cite>data_path</cite> is not specified.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.LFCNN.get_component_relevances">
<code class="descname">get_component_relevances</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.LFCNN.get_component_relevances" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute component relevances by recursive elimination</p>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.LFCNN.get_output_correlations">
<code class="descname">get_output_correlations</code><span class="sig-paren">(</span><em>y_true</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.LFCNN.get_output_correlations" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a similarity metric between each of the extracted
features and the target variable.</p>
<p>The metric is a Manhattan distance for dicrete targets, and
Spearman correlation for continuous targets.</p>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.LFCNN.plot_out_weights">
<code class="descname">plot_out_weights</code><span class="sig-paren">(</span><em>pat=None</em>, <em>t=None</em>, <em>tmin=-0.1</em>, <em>sorting='weight'</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.LFCNN.plot_out_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Plots the weights of the output layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pat</strong> (<em>int</em><em> [</em><em>0</em><em>, </em><em>self.specs</em><em>[</em><em>'n_latent'</em><em>]</em><em>)</em>) – Index of the latent component to higlight</p></li>
<li><p><strong>t</strong> (<em>int</em><em> [</em><em>0</em><em>, </em><em>self.h_params</em><em>[</em><em>'n_t'</em><em>]</em><em>)</em>) – Index of timepoint to highlight</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.LFCNN.plot_patterns">
<code class="descname">plot_patterns</code><span class="sig-paren">(</span><em>sensor_layout=None</em>, <em>sorting='l2'</em>, <em>percentile=90</em>, <em>scale=False</em>, <em>names=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.LFCNN.plot_patterns" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot informative spatial activations patterns for each class
of stimuli.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sensor_layout</strong> (<em>str</em><em> or </em><em>mne.channels.Layout</em>) – Sensor layout. See mne.channels.read_layout for details</p></li>
<li><p><strong>sorting</strong> (<em>str</em><em>, </em><em>optional</em>) – Component sorting heuristics. Defaults to ‘l2’.
See model._sorting</p></li>
<li><p><strong>scale</strong> (<em>bool</em><em>, </em><em>otional</em>) – If True will min-max scale the output. Defaults to False.</p></li>
<li><p><strong>names</strong> (<em>list of str</em><em>, </em><em>optional</em>) – Class names.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Figure</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.LFCNN.plot_spectra">
<code class="descname">plot_spectra</code><span class="sig-paren">(</span><em>fs=None</em>, <em>sorting='l2'</em>, <em>norm_spectra=None</em>, <em>log=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.LFCNN.plot_spectra" title="Permalink to this definition">¶</a></dt>
<dd><p>Plots frequency responses of the temporal convolution filters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fs</strong> (<em>float</em>) – Sampling frequency.</p></li>
<li><p><strong>sorting</strong> (<em>str optinal</em>) – Component sorting heuristics. Defaults to ‘l2’.
See model._sorting</p></li>
<li><p><strong>norm_sepctra</strong> (<em>None</em><em>, </em><em>str {'welch'</em><em>, </em><em>'ar'}</em>) – Whether to apply normalization for extracted spectra.
Defaults to None.</p></li>
<li><p><strong>log</strong> (<em>bool</em>) – Apply log-transform to the spectra.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.LFCNN.plot_waveforms">
<code class="descname">plot_waveforms</code><span class="sig-paren">(</span><em>tmin=0</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.LFCNN.plot_waveforms" title="Permalink to this definition">¶</a></dt>
<dd><p>Plots timecourses of latent components.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tmin</strong> (<em>float</em>) – Beginning of the MEG epoch with regard to reference event.
Defaults to 0.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="varcnn">
<h3>VARCNN<a class="headerlink" href="#varcnn" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="mneflow.models.VARCNN">
<em class="property">class </em><code class="descclassname">mneflow.models.</code><code class="descname">VARCNN</code><span class="sig-paren">(</span><em>Dataset</em>, <em>specs</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.VARCNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mneflow.models.BaseModel" title="mneflow.models.BaseModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">mneflow.models.BaseModel</span></code></a></p>
<p>VAR-CNN.</p>
<p>For details see [1].</p>
<p class="rubric">References</p>
<p>[1] I. Zubarev, et al., Adaptive neural network classifier for
decoding MEG signals. Neuroimage. (2019) May 4;197:425-434</p>
<dl class="method">
<dt id="mneflow.models.VARCNN.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>Dataset</em>, <em>specs</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.VARCNN.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Dataset</strong> (<em>mneflow.Dataset</em>) – </p></li>
<li><p><strong>specs</strong> (<em>dict</em>) – dictionary of model hyperparameters {</p></li>
<li><p><strong>n_latent</strong> (<em>int</em>) – Number of latent components.
Defaults to 32.</p></li>
<li><p><strong>nonlin</strong> (<em>callable</em>) – Activation function of the temporal convolution layer.
Defaults to tf.nn.relu</p></li>
<li><p><strong>filter_length</strong> (<em>int</em>) – Length of spatio-temporal kernels in the temporal
convolution layer. Defaults to 7.</p></li>
<li><p><strong>pooling</strong> (<em>int</em>) – Pooling factor of the max pooling layer. Defaults to 2</p></li>
<li><p><strong>pool_type</strong> (<em>str {'avg'</em><em>, </em><em>'max'}</em>) – Type of pooling operation. Defaults to ‘max’.</p></li>
<li><p><strong>padding</strong> (<em>str {'SAME'</em><em>, </em><em>'FULL'</em><em>, </em><em>'VALID'}</em>) – Convolution padding. Defaults to ‘SAME’.}</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.VARCNN.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.VARCNN.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Build computational graph using defined placeholder <cite>self.X</cite>
as input.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>y_pred</strong> – Output of the forward pass of the computational graph.
Prediction of the target variable.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="eegnet">
<h3>EEGNet<a class="headerlink" href="#eegnet" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="mneflow.models.EEGNet">
<em class="property">class </em><code class="descclassname">mneflow.models.</code><code class="descname">EEGNet</code><span class="sig-paren">(</span><em>Dataset</em>, <em>specs</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.EEGNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mneflow.models.BaseModel" title="mneflow.models.BaseModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">mneflow.models.BaseModel</span></code></a></p>
<p>EEGNet.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>specs</strong> (<em>dict</em>) – <dl class="simple">
<dt>n_latent<span class="classifier">int</span></dt><dd><p>Number of (temporal) convolution kernrels in the first layer.
Defaults to 8</p>
</dd>
<dt>filter_length<span class="classifier">int</span></dt><dd><p>Length of temporal filters in the first layer.
Defaults to 32</p>
</dd>
<dt>stride<span class="classifier">int</span></dt><dd><p>Stride of the average polling layers. Defaults to 4.</p>
</dd>
<dt>pooling<span class="classifier">int</span></dt><dd><p>Pooling factor of the average polling layers. Defaults to 4.</p>
</dd>
<dt>dropout<span class="classifier">float</span></dt><dd><p>Dropout coefficient.</p>
</dd>
</dl>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<p>[3] V.J. Lawhern, et al., EEGNet: A compact convolutional neural
network for EEG-based brain–computer interfaces 10 J. Neural Eng.,
15 (5) (2018), p. 056013</p>
<p>[4] Original EEGNet implementation by the authors can be found at
<a class="reference external" href="https://github.com/vlawhern/arl-eegmodels">https://github.com/vlawhern/arl-eegmodels</a></p>
<dl class="method">
<dt id="mneflow.models.EEGNet.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.EEGNet.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Build computational graph using defined placeholder self.X
as input.</p>
<p>Can be overriden in a sub-class for customized architecture.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>y_pred</strong> – Output of the forward pass of the computational graph.
Prediction of the target variable.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="fbcsp-shallownet">
<h3>FBCSP_ShallowNet<a class="headerlink" href="#fbcsp-shallownet" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="mneflow.models.FBCSP_ShallowNet">
<em class="property">class </em><code class="descclassname">mneflow.models.</code><code class="descname">FBCSP_ShallowNet</code><span class="sig-paren">(</span><em>Dataset</em>, <em>specs</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.FBCSP_ShallowNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mneflow.models.BaseModel" title="mneflow.models.BaseModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">mneflow.models.BaseModel</span></code></a></p>
<p>Shallow ConvNet model from <a class="reference internal" href="#a" id="id1"><span>[2a]</span></a>.
.. rubric:: References</p>
<dl class="citation">
<dt class="label" id="a"><span class="brackets"><a class="fn-backref" href="#id1">2a</a></span></dt>
<dd><p>Schirrmeister, R. T., Springenberg, J. T., Fiederer, L. D. J.,
Glasstetter, M., Eggensperger, K., Tangermann, M., Hutter, F. &amp; Ball, T. (2017).
Deep learning with convolutional neural networks for EEG decoding and
visualization.
Human Brain Mapping , Aug. 2017. Online: <a class="reference external" href="http://dx.doi.org/10.1002/hbm.23730">http://dx.doi.org/10.1002/hbm.23730</a></p>
</dd>
</dl>
<dl class="method">
<dt id="mneflow.models.FBCSP_ShallowNet.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>Dataset</em>, <em>specs</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.FBCSP_ShallowNet.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Dataset</strong> (<em>mneflow.Dataset</em>) – <cite>Dataset</cite> object.</p></li>
<li><p><strong>specs</strong> (<em>dict</em>) – Dictionary of model-specific hyperparameters. Must include
at least <cite>model_path</cite> - path for saving a trained model.
See <cite>Model</cite> subclass definitions for details.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.FBCSP_ShallowNet.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.FBCSP_ShallowNet.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Temporal conv_1 25 10x1 kernels</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="deep4">
<h3>Deep4<a class="headerlink" href="#deep4" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="mneflow.models.Deep4">
<em class="property">class </em><code class="descclassname">mneflow.models.</code><code class="descname">Deep4</code><span class="sig-paren">(</span><em>Dataset</em>, <em>specs</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.Deep4" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mneflow.models.BaseModel" title="mneflow.models.BaseModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">mneflow.models.BaseModel</span></code></a></p>
<p>Deep ConvNet model from <a class="reference internal" href="#b" id="id2"><span>[2b]</span></a>.
.. rubric:: References</p>
<dl class="citation">
<dt class="label" id="b"><span class="brackets"><a class="fn-backref" href="#id2">2b</a></span></dt>
<dd><p>Schirrmeister, R. T., Springenberg, J. T., Fiederer, L. D. J.,
Glasstetter, M., Eggensperger, K., Tangermann, M., Hutter, F. &amp; Ball, T. (2017).
Deep learning with convolutional neural networks for EEG decoding and
visualization.
Human Brain Mapping , Aug. 2017. Online: <a class="reference external" href="http://dx.doi.org/10.1002/hbm.23730">http://dx.doi.org/10.1002/hbm.23730</a></p>
</dd>
</dl>
<dl class="method">
<dt id="mneflow.models.Deep4.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>Dataset</em>, <em>specs</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.Deep4.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Dataset</strong> (<em>mneflow.Dataset</em>) – <cite>Dataset</cite> object.</p></li>
<li><p><strong>specs</strong> (<em>dict</em>) – Dictionary of model-specific hyperparameters. Must include
at least <cite>model_path</cite> - path for saving a trained model.
See <cite>Model</cite> subclass definitions for details.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.models.Deep4.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.models.Deep4.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Build computational graph using defined placeholder self.X
as input.</p>
<p>Can be overriden in a sub-class for customized architecture.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>y_pred</strong> – Output of the forward pass of the computational graph.
Prediction of the target variable.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="mneflow-dataset">
<h2>mneflow.Dataset<a class="headerlink" href="#mneflow-dataset" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="mneflow.data.Dataset">
<em class="property">class </em><code class="descclassname">mneflow.data.</code><code class="descname">Dataset</code><span class="sig-paren">(</span><em>h_params</em>, <em>train_batch=200</em>, <em>class_subset=None</em>, <em>combine_classes=False</em>, <em>pick_channels=None</em>, <em>decim=None</em>, <em>test_batch=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.data.Dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>TFRecords dataset from TFRecords files using the metadata.</p>
<dl class="method">
<dt id="mneflow.data.Dataset.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>h_params</em>, <em>train_batch=200</em>, <em>class_subset=None</em>, <em>combine_classes=False</em>, <em>pick_channels=None</em>, <em>decim=None</em>, <em>test_batch=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.data.Dataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize tf.data.TFRdatasets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>h_params</strong> (<em>dict</em>) – Metadata file, output of mneflow.utils.produce_tfrecords.
See mneflow.utils.produce_tfrecords for details.</p></li>
<li><p><strong>train_batch</strong> (<em>int</em><em>, </em><em>optional</em>) – Training mini-batch size. Defaults to 200.</p></li>
<li><p><strong>class_subset</strong> (<em>NoneType</em><em>, </em><em>list of int</em><em>, </em><em>optional</em>) – Pick a subset of classes from the dataset. Note that class
labels produced by mneflow are always defined as integers
in range [0 - n_classes). See meta[‘orig_classes’] for
mapping between {new_class:old_class}.
If None, all classes are used.
Defaults to None.</p></li>
<li><p><strong>combine_classes</strong> (<em>list</em><em>, </em><em>optional</em>) – Not Implemented, optional</p></li>
<li><p><strong>pick_channels</strong> (<em>NoneType</em><em>, </em><em>ndarray of int</em><em>, </em><em>optional</em>) – Indices of a subset of channels to pick for analysis.
If None, all classes are used.  Defaults to None.</p></li>
<li><p><strong>decim</strong> (<em>NoneType</em><em>, </em><em>int</em><em>, </em><em>optional</em>) – Decimation factor. Defaults to None.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.data.Dataset.class_weights">
<code class="descname">class_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.data.Dataset.class_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Weights take class proportions into account.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-mneflow.utils">
<span id="mneflow-utils"></span><h2>mneflow.utils<a class="headerlink" href="#module-mneflow.utils" title="Permalink to this headline">¶</a></h2>
<p>Specifies utility functions.</p>
<p>&#64;author: Ivan Zubarev, <a class="reference external" href="mailto:ivan&#46;zubarev&#37;&#52;&#48;aalto&#46;fi">ivan<span>&#46;</span>zubarev<span>&#64;</span>aalto<span>&#46;</span>fi</a></p>
<dl class="function">
<dt id="mneflow.utils.cont_split_indices">
<code class="descclassname">mneflow.utils.</code><code class="descname">cont_split_indices</code><span class="sig-paren">(</span><em>X</em>, <em>test_size=0.1</em>, <em>test_segments=5</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.utils.cont_split_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>X - 3d data array.</p>
</dd></dl>

<dl class="function">
<dt id="mneflow.utils.import_data">
<code class="descclassname">mneflow.utils.</code><code class="descname">import_data</code><span class="sig-paren">(</span><em>inp</em>, <em>picks=None</em>, <em>target_picks=None</em>, <em>array_keys={'X': 'X'</em>, <em>'y': 'y'}</em>, <em>transpose=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.utils.import_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Import epoch data into <cite>X, y</cite> data/target pairs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inp</strong> (<em>list</em><em>, </em><em>mne.epochs.Epochs</em><em>, </em><em>str</em>) – List of mne.epochs.Epochs or strings with filenames. If input
is a single string or Epochs object, it is first converted into
a list.</p></li>
<li><p><strong>picks</strong> (<em>ndarray of int</em><em>, </em><em>optional</em>) – Indices of channels to pick for processing. If None, all
channels are used.</p></li>
<li><p><strong>target_picks</strong> (<em>ndarray of int</em><em>, </em><em>optional</em>) – Indices of channels to pick up target variables. If None,
targets are extracted from other sources. Defaults to None.</p></li>
<li><p><strong>array_keys</strong> (<em>dict</em><em>, </em><em>optional</em>) – Dictionary mapping {‘X’: ‘data_matrix’, ‘y’: ‘labels’},
where ‘data_matrix’ and ‘labels’ are names of the corresponding
variables, if the input is paths to .mat or .npz files.
Defaults to {‘X’: ‘X’, ‘y’: ‘y’}</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p><strong>data, targets</strong> – data.shape =  [n_epochs, channels, times]</p>
<p>targets.shape =  [n_epochs, y_shape]</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mneflow.utils.leave_one_subj_out">
<code class="descclassname">mneflow.utils.</code><code class="descname">leave_one_subj_out</code><span class="sig-paren">(</span><em>meta</em>, <em>optimizer_params</em>, <em>graph_specs</em>, <em>model</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.utils.leave_one_subj_out" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform a leave-one-out cross-validation.</p>
<p>On each fold one input .tfrecord file is used as a validation set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>meta</strong> (<em>dict</em>) – Dictionary containing metadata for initializing mneflow.Dataset.
Normally meta is an output of produce_tfrecords function.</p></li>
<li><p><strong>optimizer_params</strong> (<em>dict</em>) – Dictionary of parameters for initializing mneflow.Optimizer.</p></li>
<li><p><strong>graph_specs</strong> (<em>dict</em>) – Dictionary of model-specific parameters.</p></li>
<li><p><strong>model</strong> (<em>mneflow.models.Model</em>) – Class of model to be used</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>results</strong> – List of dictionaries, containing final cost and performance
estimates on each fold of the cross-validation.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list of dict</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mneflow.utils.partition">
<code class="descclassname">mneflow.utils.</code><code class="descname">partition</code><span class="sig-paren">(</span><em>data</em>, <em>test_indices</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.utils.partition" title="Permalink to this definition">¶</a></dt>
<dd><p>Partition continuous data according to ranges defined by <cite>test_indices</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>list of ndarray</em>) – Data array to be partitioned.</p></li>
<li><p><strong>test_indices</strong> (<em>list</em>) – Contains pairs of values [start, end], indicating where the data
will be partitioned.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x_train, x_test</strong> – The data partitioned into two sets.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>lists of ndarrays</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If the shape of`test_indices` is incorrect.:</p></li>
<li><p><strong>AttributeError</strong> – If <cite>test_indices</cite> is empty.:</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mneflow.utils.preprocess">
<code class="descclassname">mneflow.utils.</code><code class="descname">preprocess</code><span class="sig-paren">(</span><em>data</em>, <em>events</em>, <em>input_type='trials'</em>, <em>val_size=0.1</em>, <em>scale=False</em>, <em>fs=None</em>, <em>scale_interval=None</em>, <em>crop_baseline=False</em>, <em>decimate=False</em>, <em>bp_filter=False</em>, <em>picks=None</em>, <em>segment=False</em>, <em>aug_stride=None</em>, <em>seq_length=None</em>, <em>transform_targets=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.utils.preprocess" title="Permalink to this definition">¶</a></dt>
<dd><p>Preprocess input data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scale</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to perform scaling to baseline. Defaults to False.</p></li>
<li><p><strong>scale_interval</strong> (<em>NoneType</em><em>, </em><em>tuple of ints</em><em> or </em><em>floats</em><em>,  </em><em>optional</em>) – Baseline definition. If None (default) scaling is
performed based on all timepoints of the epoch.
If tuple, than baseline is data[tuple[0] : tuple[1]].
Only used if scale == True.</p></li>
<li><p><strong>crop_baseline</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to crop baseline specified by ‘scale_interval’
after scaling (defaults to False).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>x_train, x_val</strong> (<em>ndarrays</em>) – Data arrays of dimensions [n_epochs, n_seq, n_ch, n_t]</p></li>
<li><p><strong>y_train, y_val</strong> (<em>ndarrays</em>) – Label arrays of dimensions [n_epochs, n_seq, n_targets]</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mneflow.utils.produce_labels">
<code class="descclassname">mneflow.utils.</code><code class="descname">produce_labels</code><span class="sig-paren">(</span><em>y</em>, <em>return_stats=True</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.utils.produce_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Produce labels array from e.g. event (unordered) trigger codes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_epochs</em><em>,</em><em>)</em>) – Array of trigger codes.</p></li>
<li><p><strong>return_stats</strong> (<em>bool</em>) – Whether to return optional outputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>inv</strong> (<em>ndarray, shape (n_epochs)</em>) – Ordered class labels.</p></li>
<li><p><strong>total_counts</strong> (<em>int, optional</em>) – Total count of events.</p></li>
<li><p><strong>class_proportions</strong> (<em>dict, optional</em>) – {new_class: proportion of new_class1 in the dataset}.</p></li>
<li><p><strong>orig_classes</strong> (<em>dict, optional</em>) – Mapping {new_class:old_class}.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mneflow.utils.produce_tfrecords">
<code class="descclassname">mneflow.utils.</code><code class="descname">produce_tfrecords</code><span class="sig-paren">(</span><em>inputs</em>, <em>savepath</em>, <em>out_name</em>, <em>fs=0</em>, <em>input_type='trials'</em>, <em>target_type='float'</em>, <em>array_keys={'X': 'X'</em>, <em>'y': 'y'}</em>, <em>val_size=0.2</em>, <em>scale=False</em>, <em>scale_interval=None</em>, <em>crop_baseline=False</em>, <em>bp_filter=False</em>, <em>decimate=False</em>, <em>combine_events=None</em>, <em>segment=False</em>, <em>aug_stride=None</em>, <em>seq_length=None</em>, <em>picks=None</em>, <em>transpose=False</em>, <em>target_picks=None</em>, <em>overwrite=True</em>, <em>savebatch=1</em>, <em>test_set=False</em>, <em>transform_targets=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.utils.produce_tfrecords" title="Permalink to this definition">¶</a></dt>
<dd><p>Produce TFRecord files from input, apply (optional) preprocessing.</p>
<p>Calling this function will convert the input data into TFRecords
format that is used to effiently store and run Tensorflow models on
the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>mne.Epochs</em><em>, </em><em>list of str</em><em>, </em><em>tuple of ndarrays</em>) – Input data.</p></li>
<li><p><strong>savepath</strong> (<em>str</em>) – A path where the output TFRecord and corresponding metadata
files will be stored.</p></li>
<li><p><strong>out_name</strong> (<em>str</em>) – Filename prefix for the output files.</p></li>
<li><p><strong>fs</strong> (<em>float</em><em>, </em><em>optional</em>) – Sampling frequency, required only if inputs are not mne.Epochs</p></li>
<li><p><strong>input_type</strong> (<em>str {'trials'</em><em>, </em><em>'continuous'</em><em>, </em><em>'seq'}</em>) – Type of input data.</p></li>
<li><p><strong>target_type</strong> (<em>str {'int'</em><em>, </em><em>'float'}</em>) – Type of target variable.
‘int’ - for classification, ‘float’ for regression problems.</p></li>
<li><p><strong>array_keys</strong> (<em>dict</em><em>, </em><em>optional</em>) – Dictionary mapping {‘X’:’data_matrix’,’y’:’labels’},
where ‘data_matrix’ and ‘labels’ are names of the
corresponding variables if the input is paths to .mat or .npz
files. Defaults to {‘X’:’X’, ‘y’:’y’}</p></li>
<li><p><strong>val_size</strong> (<em>float</em><em>, </em><em>optional</em>) – Proportion of the data to use as a validation set. Only used if
shuffle_split = True. Defaults to 0.2.</p></li>
<li><p><strong>scale</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to perform scaling to baseline. Defaults to False.</p></li>
<li><p><strong>scale_interval</strong> (<em>NoneType</em><em>, </em><em>tuple of ints</em><em> or </em><em>floats</em><em>,  </em><em>optimal</em>) – Baseline definition. If None (default) scaling is
performed based on all timepoints of the epoch.
If tuple, then baseline is data[tuple[0] : tuple[1]].
Only used if scale == True.</p></li>
<li><p><strong>crop_baseline</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to crop baseline specified by ‘scale_interval’
after scaling. Defaults to False.</p></li>
<li><p><strong>bp_filter</strong> (<em>bool</em><em>, </em><em>tuple</em><em>, </em><em>optional</em>) – Band pass filter. Tuple of int or NoneType.</p></li>
<li><p><strong>decimate</strong> (<em>False</em><em>, </em><em>int</em><em>, </em><em>optional</em>) – Whether to decimate the input data. Defaults to False.</p></li>
<li><p><strong>combine_events</strong> (<em>dict</em><em>, </em><em>optional</em>) – Dictionary for combining or otherwise manipulating lables.
Should contain mapping {old_label: new_label}. If provided and
some old_labels are not specified in keys, the corresponding
epochs are discarded.</p></li>
<li><p><strong>segment</strong> (<em>bool</em><em>, </em><em>int</em><em>, </em><em>optional</em>) – Whether to spit the data into smaller segments of specified
length.</p></li>
<li><p><strong>augment</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to apply sliding window augmentation.</p></li>
<li><p><strong>aug_stride</strong> (<em>int</em><em>, </em><em>optional</em>) – Stride of sliding window augmentation.</p></li>
<li><p><strong>picks</strong> (<em>ndarray of int</em><em>, </em><em>optional</em>) – Array of channel indices to use in decoding.</p></li>
<li><p><strong>target_picks</strong> (<em>ndarray</em><em>, </em><em>optional</em>) – Array of channel indices used to extract target variable.</p></li>
<li><p><strong>transpose</strong> (<em>bool</em><em>, </em><em>tuple</em><em>, </em><em>optional</em>) – (‘X’, ‘y’) swaps last two dimensions of both data and targets
during import.
(‘X’), does the same for data only. Default is False.</p></li>
<li><p><strong>transform_targets</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to transform the targets.</p></li>
<li><p><strong>seq_length</strong> (<em>int</em><em>, </em><em>optional</em>) – Length of segment sequence.</p></li>
<li><p><strong>overwrite</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to overwrite the metafile if it already exists at the
specified path.</p></li>
<li><p><strong>savebatch</strong> (<em>int</em>) – Number of input files to be stored in each output TFRecord
file. Defaults to 1.</p></li>
<li><p><strong>test_set</strong> (<em>str {'holdout'</em><em>, </em><em>'loso'</em><em>, </em><em>None}</em><em>, </em><em>optional</em>) – Defines if a separate holdout test set is required.
‘holdout’ saves 50% of the validation set
‘loso’ saves the whole dataset in original order for
leave-one-subject-out cross-validation.
None does not leave a separate test set. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>meta</strong> – Metadata associated with the processed dataset. Contains all
the information about the dataset required for further
processing with mneflow.
Whenever the function is called the copy of metadata is also
saved to savepath/meta.pkl so it can be restored at any time.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Pre-processing functions are implemented mostly for for convenience
when working with array inputs. When working with mne.epochs the
use of the corresponding mne functions is preferred.</p>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">meta</span> <span class="o">=</span> <span class="n">mneflow</span><span class="o">.</span><span class="n">produce_tfrecords</span><span class="p">(</span><span class="n">input_paths</span><span class="p">,</span> \<span class="o">**</span><span class="n">import_opts</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mneflow.utils.scale_to_baseline">
<code class="descclassname">mneflow.utils.</code><code class="descname">scale_to_baseline</code><span class="sig-paren">(</span><em>X_</em>, <em>baseline=None</em>, <em>crop_baseline=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.utils.scale_to_baseline" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform global scaling based on a specified baseline.</p>
<p>Subtracts the mean and divides by the standard deviation of the
amplitude of all channels during the baseline interval. If input
contains 306 channels, performs separate scaling for magnetometers
and gradiometers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>ndarray</em>) – Data array with dimensions [n_epochs, n_channels, time].</p></li>
<li><p><strong>baseline</strong> (<em>tuple of int</em><em>, </em><em>None</em>) – Baseline definition (in samples). If baseline == None the whole
epoch is used for scaling.</p></li>
<li><p><strong>crop_baseline</strong> (<em>bool</em>) – Whether to crop the baseline after scaling is applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X</strong> – Scaled data array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-mneflow.layers">
<span id="mneflow-layers"></span><h2>mneflow.layers<a class="headerlink" href="#module-mneflow.layers" title="Permalink to this headline">¶</a></h2>
<p>Defines mneflow.layers for mneflow.models.</p>
<p>&#64;author: Ivan Zubarev, <a class="reference external" href="mailto:ivan&#46;zubarev&#37;&#52;&#48;aalto&#46;fi">ivan<span>&#46;</span>zubarev<span>&#64;</span>aalto<span>&#46;</span>fi</a></p>
<dl class="class">
<dt id="mneflow.layers.BaseLayer">
<em class="property">class </em><code class="descclassname">mneflow.layers.</code><code class="descname">BaseLayer</code><span class="sig-paren">(</span><em>size</em>, <em>nonlin</em>, <em>specs</em>, <em>**args</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.BaseLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.engine.base_layer.Layer</span></code></p>
<dl class="method">
<dt id="mneflow.layers.BaseLayer.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>size</em>, <em>nonlin</em>, <em>specs</em>, <em>**args</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.BaseLayer.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="mneflow.layers.DeMixing">
<em class="property">class </em><code class="descclassname">mneflow.layers.</code><code class="descname">DeMixing</code><span class="sig-paren">(</span><em>scope='demix'</em>, <em>size=None</em>, <em>nonlin=&lt;function identity&gt;</em>, <em>axis=-1</em>, <em>specs={}</em>, <em>**args</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.DeMixing" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mneflow.layers.BaseLayer" title="mneflow.layers.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">mneflow.layers.BaseLayer</span></code></a></p>
<p>Spatial demixing Layer</p>
<dl class="method">
<dt id="mneflow.layers.DeMixing.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>scope='demix'</em>, <em>size=None</em>, <em>nonlin=&lt;function identity&gt;</em>, <em>axis=-1</em>, <em>specs={}</em>, <em>**args</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.DeMixing.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="mneflow.layers.DeMixing.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.DeMixing.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the variables of the layer (optional, for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>
can override if they need a state-creation step in-between
layer instantiation and layer call.</p>
<p>This is typically used to create the weights of <cite>Layer</cite> subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Instance of <cite>TensorShape</cite>, or list of instances of
<cite>TensorShape</cite> if the layer expects a list of inputs
(one instance per input).</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.layers.DeMixing.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>training=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.DeMixing.call" title="Permalink to this definition">¶</a></dt>
<dd><p>This is where the layer’s logic lives.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – Input tensor, or list/tuple of input tensors.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor or list/tuple of tensors.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.layers.DeMixing.get_config">
<code class="descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.DeMixing.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mneflow.layers.Dense">
<em class="property">class </em><code class="descclassname">mneflow.layers.</code><code class="descname">Dense</code><span class="sig-paren">(</span><em>scope='fc'</em>, <em>size=None</em>, <em>nonlin=&lt;function identity&gt;</em>, <em>specs={}</em>, <em>**args</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.Dense" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mneflow.layers.BaseLayer" title="mneflow.layers.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">mneflow.layers.BaseLayer</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.engine.base_layer.Layer</span></code></p>
<p>Fully-connected layer</p>
<dl class="method">
<dt id="mneflow.layers.Dense.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>scope='fc'</em>, <em>size=None</em>, <em>nonlin=&lt;function identity&gt;</em>, <em>specs={}</em>, <em>**args</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.Dense.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="mneflow.layers.Dense.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.Dense.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the variables of the layer (optional, for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>
can override if they need a state-creation step in-between
layer instantiation and layer call.</p>
<p>This is typically used to create the weights of <cite>Layer</cite> subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Instance of <cite>TensorShape</cite>, or list of instances of
<cite>TensorShape</cite> if the layer expects a list of inputs
(one instance per input).</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.layers.Dense.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>training=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.Dense.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Dense layer currying, to apply layer to any input tensor <cite>x</cite></p>
</dd></dl>

<dl class="method">
<dt id="mneflow.layers.Dense.get_config">
<code class="descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.Dense.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mneflow.layers.LFTConv">
<em class="property">class </em><code class="descclassname">mneflow.layers.</code><code class="descname">LFTConv</code><span class="sig-paren">(</span><em>scope='lf_conv'</em>, <em>size=32</em>, <em>nonlin=&lt;function relu&gt;</em>, <em>filter_length=7</em>, <em>pooling=2</em>, <em>padding='SAME'</em>, <em>specs={}</em>, <em>**args</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.LFTConv" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mneflow.layers.BaseLayer" title="mneflow.layers.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">mneflow.layers.BaseLayer</span></code></a></p>
<p>Stackable temporal convolutional layer, interpreatble (LF)</p>
<dl class="method">
<dt id="mneflow.layers.LFTConv.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>scope='lf_conv'</em>, <em>size=32</em>, <em>nonlin=&lt;function relu&gt;</em>, <em>filter_length=7</em>, <em>pooling=2</em>, <em>padding='SAME'</em>, <em>specs={}</em>, <em>**args</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.LFTConv.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="mneflow.layers.LFTConv.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.LFTConv.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the variables of the layer (optional, for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>
can override if they need a state-creation step in-between
layer instantiation and layer call.</p>
<p>This is typically used to create the weights of <cite>Layer</cite> subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Instance of <cite>TensorShape</cite>, or list of instances of
<cite>TensorShape</cite> if the layer expects a list of inputs
(one instance per input).</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.layers.LFTConv.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>training=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.LFTConv.call" title="Permalink to this definition">¶</a></dt>
<dd><p>This is where the layer’s logic lives.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – Input tensor, or list/tuple of input tensors.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor or list/tuple of tensors.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.layers.LFTConv.get_config">
<code class="descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.LFTConv.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mneflow.layers.TempPooling">
<em class="property">class </em><code class="descclassname">mneflow.layers.</code><code class="descname">TempPooling</code><span class="sig-paren">(</span><em>scope='pool'</em>, <em>stride=2</em>, <em>pooling=2</em>, <em>specs={}</em>, <em>padding='SAME'</em>, <em>pool_type='max'</em>, <em>**args</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.TempPooling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mneflow.layers.BaseLayer" title="mneflow.layers.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">mneflow.layers.BaseLayer</span></code></a></p>
<dl class="method">
<dt id="mneflow.layers.TempPooling.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>scope='pool'</em>, <em>stride=2</em>, <em>pooling=2</em>, <em>specs={}</em>, <em>padding='SAME'</em>, <em>pool_type='max'</em>, <em>**args</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.TempPooling.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="mneflow.layers.TempPooling.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.TempPooling.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the variables of the layer (optional, for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>
can override if they need a state-creation step in-between
layer instantiation and layer call.</p>
<p>This is typically used to create the weights of <cite>Layer</cite> subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Instance of <cite>TensorShape</cite>, or list of instances of
<cite>TensorShape</cite> if the layer expects a list of inputs
(one instance per input).</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.layers.TempPooling.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.TempPooling.call" title="Permalink to this definition">¶</a></dt>
<dd><p>This is where the layer’s logic lives.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – Input tensor, or list/tuple of input tensors.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor or list/tuple of tensors.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.layers.TempPooling.get_config">
<code class="descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.TempPooling.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mneflow.layers.VARConv">
<em class="property">class </em><code class="descclassname">mneflow.layers.</code><code class="descname">VARConv</code><span class="sig-paren">(</span><em>scope='var_conv'</em>, <em>size=32</em>, <em>nonlin=&lt;function relu&gt;</em>, <em>filter_length=7</em>, <em>pooling=2</em>, <em>padding='SAME'</em>, <em>specs={}</em>, <em>**args</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.VARConv" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mneflow.layers.BaseLayer" title="mneflow.layers.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">mneflow.layers.BaseLayer</span></code></a></p>
<p>Stackable temporal convolutional layer, interpreatble (LF)</p>
<dl class="method">
<dt id="mneflow.layers.VARConv.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>scope='var_conv'</em>, <em>size=32</em>, <em>nonlin=&lt;function relu&gt;</em>, <em>filter_length=7</em>, <em>pooling=2</em>, <em>padding='SAME'</em>, <em>specs={}</em>, <em>**args</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.VARConv.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="mneflow.layers.VARConv.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.VARConv.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the variables of the layer (optional, for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>
can override if they need a state-creation step in-between
layer instantiation and layer call.</p>
<p>This is typically used to create the weights of <cite>Layer</cite> subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Instance of <cite>TensorShape</cite>, or list of instances of
<cite>TensorShape</cite> if the layer expects a list of inputs
(one instance per input).</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.layers.VARConv.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>training=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.VARConv.call" title="Permalink to this definition">¶</a></dt>
<dd><p>This is where the layer’s logic lives.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – Input tensor, or list/tuple of input tensors.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor or list/tuple of tensors.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mneflow.layers.VARConv.get_config">
<code class="descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mneflow.layers.VARConv.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="changelog.html" class="btn btn-neutral float-right" title="History" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="intro.html" class="btn btn-neutral float-left" title="MNEflow" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Ivan Zubarev

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>